# Editerra RAC-CAG Coding Assistant

> AI-Powered Code Intelligence for Complex Projects

[![License: BSL 1.1](https://img.shields.io/badge/License-BSL%201.1-blue.svg)](LICENSE.md)
[![Python Version](https://img.shields.io/badge/python-3.9%2B-blue)](https://python.org)
[![Status](https://img.shields.io/badge/status-alpha-orange)](https://github.com/VSLinea/editerra-racag)

## ğŸš€ What is Editerra RAC-CAG?

**Editerra RAC-CAG** (Retrieval-Augmented Context-Aware Generator) is a sophisticated code intelligence engine that helps AI understand your entire codebase - not just the files you have open.

## âš¡ Installation (One Command!)

```bash
# Install everything automatically
pip install editerra-racag
```

**That's it!** All dependencies auto-install:
- âœ… Vector database (ChromaDB)
- âœ… LLM clients (OpenAI, Ollama)
- âœ… Code parsers (tree-sitter)
- âœ… API server (FastAPI)
- âœ… CLI tools
- âœ… ~20 Python packages

**No Docker. No complex setup. No manual configuration.**

### Key Features

- ğŸ§  **Deep Codebase Understanding** - Vectorizes your entire project using advanced chunking
- ğŸ” **Smart Context Retrieval** - Hybrid AI scoring (cosine similarity + LLM reranking)
- ğŸ¤– **Works with ANY LLM** - OpenAI, Anthropic, Azure, Ollama (local/free), and more
- ğŸ“¦ **Three Ways to Use** - Python CLI, VS Code Extension, or MCP Server
- ğŸ”’ **Privacy-First** - All data stored locally in ChromaDB
- âš¡ **Real-Time Updates** - Incremental indexing as you code
- ğŸŒ **Multi-Language** - Python, TypeScript, Swift, Java, Go, and more

## ğŸ¯ Quick Start

### Python Package (CLI)

```bash
# Install
pip install editerra-racag

# Initialize in your project
cd /path/to/your/project
editerra-racag init

# Index your codebase
editerra-racag index

# Query your codebase
editerra-racag query "Where is authentication handled?"

# Start watching for changes
editerra-racag watch
```

### VS Code Extension

1. Install from [VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=editerra.racag) *(coming soon)*
2. Open any project
3. Run: **"Editerra RAC-CAG: Index Workspace"**
4. Start coding with enhanced AI context!

### MCP Server (for Claude Desktop)

```json
{
  "mcpServers": {
    "editerra-racag": {
      "command": "editerra-racag-mcp",
      "args": ["--workspace", "${workspaceFolder}"],
      "env": {
        "OPENAI_API_KEY": "your-key-here"
      }
    }
  }
}
```

## ğŸ”¥ Why Editerra RAC-CAG?

| Problem | Solution |
|---------|----------|
| AI only sees open files | **Indexes entire codebase** |
| Generic vector search is dumb | **Hybrid scoring** (cosine + LLM) |
| Locked to one AI provider | **Multi-LLM support** (OpenAI, Claude, Ollama) |
| Privacy concerns | **Local-first** (ChromaDB on disk) |
| Expensive API calls | **Free option** (Ollama local models) |

## ğŸ“Š How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Your Code   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. Chunking (tree-sitter)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Semantic    â”‚
â”‚ Chunks      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 2. Embedding (LLM of choice)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChromaDB    â”‚
â”‚ (Local)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 3. Query + Rerank
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Smart       â”‚
â”‚ Context     â”‚â”€â”€â–¶ GitHub Copilot, Claude, ChatGPT
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Supported Languages

âœ… Python  
âœ… TypeScript / JavaScript  
âœ… Swift  
âœ… Java  
âœ… Go  
âœ… Rust  
âœ… C / C++  
âœ… Markdown  
âœ… JSON / YAML  

*More coming soon!*

## ğŸ¤– Supported LLM Providers

| Provider | Embeddings | Reranking | Cost | Status |
|----------|-----------|-----------|------|--------|
| **OpenAI** | text-embedding-3-large | gpt-4o-mini | $ | âœ… Ready |
| **Ollama** | nomic-embed-text | llama3.1 | FREE | âœ… Ready |
| Anthropic | voyage-3 | claude-3-haiku | $ | ğŸš§ Coming |
| Azure OpenAI | Same as OpenAI | Same as OpenAI | $ | ğŸš§ Coming |
| Google Vertex | text-embedding-004 | gemini-1.5-flash | $ | ğŸš§ Coming |
| Cohere | embed-english-v3 | command-r | $ | ğŸš§ Coming |

Choose your provider in `.editerra-racag.yaml`:

```yaml
llm_provider: "ollama"  # Free & local!

ollama:
  base_url: "http://localhost:11434"
  embedding_model: "nomic-embed-text"
  rerank_model: "llama3.1:8b"
```

## âš™ï¸ Configuration

Create `.editerra-racag.yaml` in your project root:

```yaml
# Project settings
project_name: "MyProject"
collection_name: "myproject_chunks"

# Paths
db_path: ".racag/db"
output_path: ".racag/output"

# LLM Provider
llm_provider: "openai"  # or "ollama", "anthropic", etc.

# OpenAI settings
openai:
  api_key: "${OPENAI_API_KEY}"
  embedding_model: "text-embedding-3-large"
  rerank_model: "gpt-4o-mini"

# Indexing
watch_enabled: true
exclude_dirs:
  - "node_modules"
  - ".git"
  - "build"
  - "dist"
```

## ğŸ“š Documentation

- [Installation Guide](docs/installation.md) *(coming soon)*
- [Configuration Reference](docs/configuration.md) *(coming soon)*
- [LLM Provider Setup](docs/llm-providers.md) *(coming soon)*
- [Architecture Overview](docs/RACAG_STANDALONE_ANALYSIS.md)
- [API Reference](docs/api-reference.md) *(coming soon)*

## ğŸ—ï¸ Project Status

**Current Status:** ğŸš§ Alpha Development

- [x] Core RACAG engine
- [x] Architecture design
- [x] Business Source License
- [ ] Multi-LLM provider abstraction
- [ ] Configuration system refactoring
- [ ] Python package (PyPI)
- [ ] VS Code extension
- [ ] MCP server
- [ ] Comprehensive documentation

**Target Launch:** Early January 2026

## ğŸ“ˆ Roadmap

### Phase 1 (Week 1) - Core Refactoring
- [ ] Dynamic configuration system
- [ ] Multi-LLM provider support (OpenAI, Ollama)
- [ ] Remove hardcoded paths

### Phase 2 (Week 2) - Python Package
- [ ] CLI interface
- [ ] PyPI publishing
- [ ] Tree-sitter grammar management

### Phase 3 (Week 3-4) - VS Code Extension
- [ ] Extension development
- [ ] Copilot integration
- [ ] Real-time indexing

### Phase 4 (Week 5) - MCP Server
- [ ] MCP protocol implementation
- [ ] Claude Desktop integration
- [ ] Testing with Cline/Continue.dev

### Phase 5 (Week 6) - Documentation & Launch
- [ ] Comprehensive docs
- [ ] Demo videos
- [ ] Marketing materials

## ğŸ’° License & Pricing

**License:** Business Source License 1.1 (converts to Apache 2.0 after 3 years)

### Free Tier
âœ… Individuals (unlimited)  
âœ… Small teams (< 10 developers)  
âœ… Open source projects  
âœ… Educational use  

### Pro Tier ($19/user/month)
- Teams (10-100 developers)
- Priority support
- Private LLM integration
- Advanced analytics

### Enterprise (Custom)
- Unlimited developers
- White-label deployment
- On-premise installation
- SLA & dedicated support

[See full license details](LICENSE.md)

## ğŸ¤ Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines. *(coming soon)*

**Areas we need help:**
- Additional LLM provider integrations
- More tree-sitter language grammars
- Documentation improvements
- Bug reports & feature requests

## ğŸ™ Acknowledgments

- Built on [ChromaDB](https://github.com/chroma-core/chroma) for vector storage
- Uses [tree-sitter](https://github.com/tree-sitter/tree-sitter) for code parsing
- Inspired by the need for better codebase understanding in AI tools

## ğŸ“§ Support & Contact

- **Documentation:** [docs/](docs/)
- **Issues:** [GitHub Issues](https://github.com/VSLinea/editerra-racag/issues)
- **Discussions:** [GitHub Discussions](https://github.com/VSLinea/editerra-racag/discussions)
- **Email:** support@editerra.io
- **Commercial Licensing:** licensing@editerra.io

## â­ Star Us!

If you find Editerra RAC-CAG useful, please give us a star! It helps others discover the project.

---

**Made with â¤ï¸ by VSLinea**

*Editerra RAC-CAG - Making AI understand your code, not just read it.*
